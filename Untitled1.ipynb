{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpnxfgZTMQUxQiIgL6mpGL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sidduonline2003/Machinelearningmodels/blob/main-model/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDbYPXhAy__u",
        "outputId": "5283025f-9239-43c6-b4a6-0dc9795b01c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_directory = '/content/drive/MyDrive/B14_Projects/skin-disease-datasaet/train_set'"
      ],
      "metadata": {
        "id": "oxh3Z-0T0VIC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJPwKh9A0jLl",
        "outputId": "42e586bc-49c8-4d0a-9f6b-45745cef603d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import sklearn.model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.decomposition import PCA\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- Data Loading and Preprocessing ---\n",
        "\n",
        "def load_and_preprocess_images(data_dir, image_size=(64, 64)):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for class_folder in os.listdir(data_dir):\n",
        "        class_path = os.path.join(data_dir, class_folder)\n",
        "        if os.path.isdir(class_path):\n",
        "            for image_file in os.listdir(class_path):\n",
        "                image_path = os.path.join(class_path, image_file)\n",
        "                try:\n",
        "                    img = cv2.imread(image_path)\n",
        "                    if img is None:\n",
        "                        print(f\"Warning: Could not load image {image_path}\")\n",
        "                        continue\n",
        "\n",
        "                    img = cv2.resize(img, image_size)\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                    images.append(img.flatten())\n",
        "                    labels.append(class_folder)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {image_path}: {e}\")\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "\n",
        "# --- Training ---\n",
        "\n",
        "data_directory = \"/content/drive/MyDrive/skin-disease-datasaet/train_set\"  # **Your Google Drive path**\n",
        "image_size = (64, 64)  # You can adjust this\n",
        "\n",
        "images, labels = load_and_preprocess_images(data_directory, image_size)\n",
        "\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
        "    images, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# PCA\n",
        "n_components = 256  # Adjust this as needed for performance/accuracy trade-off\n",
        "pca = PCA(n_components=n_components)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# Train a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000) # Increased max_iter\n",
        "model.fit(X_train_pca, y_train)\n",
        "\n",
        "\n",
        "# --- Evaluation ---\n",
        "y_pred = model.predict(X_test_pca)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "\n",
        "\n",
        "# --- Prediction on a new image ---\n",
        "\n",
        "def predict_disease(image_path, model, image_size, pca): # Add pca as argument\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        return \"Error: Could not load image\"\n",
        "\n",
        "    img = cv2.resize(img, image_size)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img = img.flatten().reshape(1, -1)\n",
        "    img_pca = pca.transform(img)  # Apply PCA\n",
        "    prediction = model.predict(img_pca)\n",
        "    return prediction[0]\n",
        "\n",
        "\n",
        "new_image_path = \"/content/drive/MyDrive/skin-disease-datasaet/test_set/BA- cellulitis/BA- cellulitis (1).webp\"  # **Your Google Drive path** # Example path - replace\n",
        "predicted_disease = predict_disease(new_image_path, model, image_size, pca)  # Pass pca to the function\n",
        "print(f\"Predicted Disease: {predicted_disease}\")\n",
        "\n",
        "\n",
        "\n",
        "# --- Saving the Model ---\n",
        "model_filename = \"/content/drive/MyDrive/skin_disease_model.pkl\"  # Saving in Google Drive\n",
        "with open(model_filename, 'wb') as file:\n",
        "    pickle.dump((model, pca), file) # Save both model and pca\n",
        "\n",
        "print(f\"Model saved to {model_filename}\")\n",
        "\n",
        "\n",
        "# --- Loading the saved model (Optional) ---\n",
        "# with open(model_filename, 'rb') as file:\n",
        "#     loaded_model, loaded_pca = pickle.load(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kM3ogbDC0nAc",
        "outputId": "34b1fd0e-a49a-4a79-b1ad-7b696d1fcaf9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Accuracy: 0.6378378378378379\n",
            "Predicted Disease: BA- cellulitis\n",
            "Model saved to /content/drive/MyDrive/skin_disease_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import sklearn.model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.decomposition import PCA\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- Data Loading and Preprocessing ---\n",
        "\n",
        "def load_and_preprocess_images(data_dir, image_size=(64, 64)):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for class_folder in os.listdir(data_dir):\n",
        "        class_path = os.path.join(data_dir, class_folder)\n",
        "        if os.path.isdir(class_path):\n",
        "            for image_file in os.listdir(class_path):\n",
        "                image_path = os.path.join(class_path, image_file)\n",
        "                try:\n",
        "                    img = cv2.imread(image_path)\n",
        "                    if img is None:\n",
        "                        print(f\"Warning: Could not load image {image_path}\")\n",
        "                        continue\n",
        "\n",
        "                    img = cv2.resize(img, image_size)\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                    images.append(img.flatten())\n",
        "                    labels.append(class_folder)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {image_path}: {e}\")\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "\n",
        "# --- Training ---\n",
        "\n",
        "data_directory = \"/content/drive/MyDrive/skin-disease-datasaet/train_set\"  # **Your Google Drive path**\n",
        "image_size = (64, 64)  # You can adjust this\n",
        "\n",
        "images, labels = load_and_preprocess_images(data_directory, image_size)\n",
        "\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
        "    images, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# PCA\n",
        "n_components = 256  # Adjust as needed\n",
        "pca = PCA(n_components=n_components)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "\n",
        "# Train a Logistic Regression model\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42), #Added RandomForestClassifier\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42), #Added GradientBoostingClassifier\n",
        "    \"SVM (Linear)\": SVC(kernel='linear', C=1), #Added SVM with Linear Kernel\n",
        "    \"SVM (RBF)\": SVC(kernel='rbf', C=1, gamma='scale') #Added SVM with RBF Kernel\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "results = {}  # Store results\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Training {model_name}...\")\n",
        "    model.fit(X_train_pca, y_train)\n",
        "    y_pred = model.predict(X_test_pca)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results[model_name] = accuracy\n",
        "    print(f\"{model_name} Accuracy: {accuracy}\")\n",
        "\n",
        "\n",
        "# Find the best model\n",
        "best_model_name = max(results, key=results.get)\n",
        "best_accuracy = results[best_model_name]\n",
        "print(f\"\\nBest Model: {best_model_name} with Accuracy: {best_accuracy}\")\n",
        "\n",
        "# --- Prediction on a new image ---\n",
        "\n",
        "def predict_disease(image_path, model, image_size, pca): # Add pca as argument\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        return \"Error: Could not load image\"\n",
        "\n",
        "    img = cv2.resize(img, image_size)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img = img.flatten().reshape(1, -1)\n",
        "    img_pca = pca.transform(img)  # Apply PCA\n",
        "    prediction = model.predict(img_pca)\n",
        "    return prediction[0]\n",
        "\n",
        "\n",
        "new_image_path = \"/content/drive/MyDrive/skin-disease-datasaet/test_set/BA- cellulitis/BA- cellulitis (1).webp\"  # **Your Google Drive path** # Example path - replace\n",
        "predicted_disease = predict_disease(new_image_path, model, image_size, pca)  # Pass pca to the function\n",
        "print(f\"Predicted Disease: {predicted_disease}\")\n",
        "\n",
        "\n",
        "\n",
        "# When saving, save the best model and pca:\n",
        "with open(model_filename, 'wb') as file:\n",
        "    pickle.dump((models[best_model_name], pca), file) #Saving the best model\n",
        "\n",
        "# --- Loading the saved model (Optional) ---\n",
        "# with open(model_filename, 'rb') as file:\n",
        "#     loaded_model, loaded_pca = pickle.load(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF-TwSFr3w7z",
        "outputId": "39553a09-3c84-408b-843f-b54bc16ecb5b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Training Logistic Regression...\n",
            "Logistic Regression Accuracy: 0.6324324324324324\n",
            "Training Random Forest...\n",
            "Random Forest Accuracy: 0.6972972972972973\n",
            "Training Gradient Boosting...\n",
            "Gradient Boosting Accuracy: 0.6486486486486487\n",
            "Training SVM (Linear)...\n",
            "SVM (Linear) Accuracy: 0.6378378378378379\n",
            "Training SVM (RBF)...\n",
            "SVM (RBF) Accuracy: 0.6\n",
            "\n",
            "Best Model: Random Forest with Accuracy: 0.6972972972972973\n",
            "Predicted Disease: BA- cellulitis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from PIL import Image  # For working with images\n",
        "import pickle\n",
        "\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "# --- Custom Dataset Class ---\n",
        "class SkinDiseaseDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        self.classes = np.unique(labels)  # Store unique class names\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = np.where(self.classes == self.labels[idx])[0][0] # Convert label to numerical index\n",
        "\n",
        "        if self.transform:\n",
        "          # Ensure the image is in PIL format before applying transforms\n",
        "          image = Image.fromarray(image).convert(\"RGB\")  # Convert to PIL Image and to RGB\n",
        "          image = self.transform(image)\n",
        "\n",
        "        return image, label  # Return transformed image and numerical label\n",
        "\n",
        "\n",
        "# --- Data Loading and Preprocessing ---\n",
        "def load_and_preprocess_images(data_dir, image_size=(224, 224)): # Resizing to 224x224, a common size for pre-trained models\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for class_folder in os.listdir(data_dir):\n",
        "        class_path = os.path.join(data_dir, class_folder)\n",
        "        if os.path.isdir(class_path):\n",
        "            for image_file in os.listdir(class_path):\n",
        "                image_path = os.path.join(class_path, image_file)\n",
        "                try:\n",
        "                    img = cv2.imread(image_path)\n",
        "                    if img is None:\n",
        "                        print(f\"Warning: Could not load image {image_path}\")\n",
        "                        continue\n",
        "\n",
        "                    img = cv2.resize(img, image_size)\n",
        "                    images.append(img)  # Store as NumPy array\n",
        "                    labels.append(class_folder)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {image_path}: {e}\")\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "\n",
        "\n",
        "# Set data directory and image size\n",
        "data_directory = \"/content/drive/MyDrive/skin-disease-datasaet/train_set\"  # Replace with your path\n",
        "image_size = (224, 224)\n",
        "\n",
        "\n",
        "images, labels = load_and_preprocess_images(data_directory, image_size)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# --- Transforms ---\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),        # Data augmentation\n",
        "    transforms.RandomRotation(10),           # Data augmentation\n",
        "    transforms.ToTensor(),                  # Convert to tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet stats\n",
        "])\n",
        "\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = SkinDiseaseDataset(X_train, y_train, transform=train_transforms)\n",
        "test_dataset = SkinDiseaseDataset(X_test, y_test, transform=test_transforms)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # Adjust batch size as needed\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "\n",
        "# --- Model Definition (using transfer learning) ---\n",
        "model = models.resnet18(pretrained=True)  # Use a pre-trained ResNet18 model\n",
        "\n",
        "# Modify the classifier (last layer) to match the number of classes in your dataset\n",
        "num_classes = len(np.unique(labels))  # Determine number of classes automatically\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "# --- Training Loop ---\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer is common\n",
        "\n",
        "\n",
        "num_epochs = 10  # Adjust as needed\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "# --- Evaluation ---\n",
        "model.eval() # Evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():  #No need to calculate gradients during evaluation\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "# --- Save the model and classes---\n",
        "model_filename = \"/content/drive/MyDrive/pytorch_skin_disease_model.pth\"  # Saving in Google Drive\n",
        "torch.save({ 'model_state_dict': model.state_dict(),\n",
        "            'classes': train_dataset.classes  # include classes\n",
        "            }, model_filename)\n",
        "print(f\"Model saved to {model_filename}\")\n",
        "\n",
        "\n",
        "\n",
        "# --- Loading the saved model (Optional) ---\n",
        "# model = models.resnet18(pretrained=False) #Note : pretrained=False as we load the weights\n",
        "# num_ftrs = model.fc.in_features\n",
        "# model.fc = nn.Linear(num_ftrs, num_classes) #replace the last layer based on the number of classes loaded below\n",
        "# checkpoint = torch.load(model_filename, map_location=device)\n",
        "# model.load_state_dict(checkpoint['model_state_dict'])\n",
        "# loaded_classes = checkpoint['classes']\n",
        "# model.to(device) #move to device if available\n",
        "# model.eval()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- Prediction on a new image ---\n",
        "def predict_disease(image_path, model, image_size, transform, classes):  # Added classes\n",
        "    try:\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None:\n",
        "            return \"Error: Could not load image\"\n",
        "        img = cv2.resize(img, image_size)\n",
        "        # Convert to PIL Image\n",
        "        img = Image.fromarray(img).convert(\"RGB\") #convert to rgb\n",
        "        img_transformed = transform(img)\n",
        "        img_transformed = img_transformed.unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
        "\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(img_transformed)\n",
        "            _, predicted_idx = torch.max(outputs, 1)\n",
        "\n",
        "\n",
        "\n",
        "        predicted_class = classes[predicted_idx.item()]  # convert to class name\n",
        "\n",
        "\n",
        "\n",
        "        return predicted_class\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during prediction: {e}\")\n",
        "        return \"Error during prediction\"\n",
        "\n",
        "\n",
        "\n",
        "new_image_path = \"/content/drive/MyDrive/skin-disease-datasaet/test_set/BA- cellulitis/BA- cellulitis (11).webp\" # Example path replace this\n",
        "transform = test_transforms # use test transforms here\n",
        "\n",
        "\n",
        "predicted_disease = predict_disease(new_image_path, model, image_size, transform, train_dataset.classes)  # Passing the loaded classes\n",
        "\n",
        "print(f\"Predicted Disease: {predicted_disease}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amth0U_250am",
        "outputId": "ec525c95-caa2-4a61-cb3e-ab00d8d34572"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 137MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.9873\n",
            "Epoch [2/10], Loss: 0.7084\n",
            "Epoch [3/10], Loss: 0.4606\n",
            "Epoch [4/10], Loss: 0.3413\n",
            "Epoch [5/10], Loss: 0.1924\n",
            "Epoch [6/10], Loss: 0.2767\n",
            "Epoch [7/10], Loss: 0.1837\n",
            "Epoch [8/10], Loss: 0.2875\n",
            "Epoch [9/10], Loss: 0.4105\n",
            "Epoch [10/10], Loss: 0.4719\n",
            "Test Accuracy: 82.16%\n",
            "Model saved to /content/drive/MyDrive/pytorch_skin_disease_model.pth\n",
            "Predicted Disease: Error: Could not load image\n"
          ]
        }
      ]
    }
  ]
}